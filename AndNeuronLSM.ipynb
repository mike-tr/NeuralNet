{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0b47b01fbeacb6918fe178353ac26b8951e929afac8e10f32a05608fcfdb3257b",
   "display_name": "Python 3.9.2 64-bit ('cv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## How the training Works\n",
    "\n",
    "* consider there is an input X, that should yield a positive answer 1.\n",
    "* we want to tweak the weights w, such that w * x > 0\n",
    "* we add the bias to x therefore x(n+1) = 1\n",
    "\n",
    "### Notice: w is the same shape as x.\n",
    "\n",
    "* consider swapping w to x ->  it will result in x*x \n",
    "* notice that x*x is a dot product and therefore be a positive number,\n",
    "* x\\*x = x(1 to n)\\*x(1 to n) + x(n+1)\\*x(n+1) >= x(n+1)\\*x(n+1) = 1\n",
    "\n",
    "hence if w = x on the next test it will score > 0 given the same x.\n",
    "\n",
    "### We want to keep the changes\n",
    "* we do not wish to completly override w.\n",
    "* therefore we say w = w + X\n",
    "\n",
    "notice that by the same reasoning w(new)\\*x > w(old)\\*x.\n",
    "\n",
    "\n",
    "### Negative exmpales\n",
    "\n",
    "* on the other hand consider X and y being negative,\n",
    "* hence we want w * X < 0\n",
    "\n",
    "####  Notice : \n",
    "* therefore consider -x * x would be a negative number.\n",
    "* hence if we set w = w - x => w(new)\\*x < w(old)\\*x\n",
    "\n",
    "thuse there is a better chance we will get a score less then 0 next try.\n",
    "\n",
    "\n",
    "### Normalizing X\n",
    "* another issue would be that not all inputs are equal\n",
    "* the input \\[1, 1\\] will have 10% of the effect of the input \\[10, 10\\] on the weights.\n",
    "* therefore we normalize, a.k.a we want the absolute sum of all cells in input to be exactly 1.\n",
    "\n",
    "\n",
    "### Normalizing effect\n",
    "* again notice that x.normalzie() * x > 0\n",
    "* hence if we say w = w + x.normalized we will score better.\n",
    "\n",
    "## Final algorithm :\n",
    "\n",
    ">if y = 1 do:\n",
    "\n",
    ">>   w = w + x.normalzied()\n",
    "\n",
    "> else \n",
    "\n",
    ">>    w = w - x.normalzied()\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neuron import Neuron"
   ]
  },
  {
   "source": [
    "## Test on AND "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 197
    }
   ],
   "source": [
    "# A AND B or B and C\n",
    "data = np.array([\n",
    "    # A  B  C  O\n",
    "    [0, 0, 0, -1],\n",
    "    [0, 0, 1, -1],\n",
    "    [0, 1, 0, -1],\n",
    "    [0, 1, 1, 1],\n",
    "    [1, 0, 0, -1],\n",
    "    [1, 0, 1, -1],\n",
    "    [1, 1, 0, 1],\n",
    "    [1, 1, 1, 1],\n",
    "])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0]\n [0 0 1]\n [0 1 0]\n [0 1 1]\n [1 0 0]\n [1 0 1]\n [1 1 0]\n [1 1 1]]\n[[-1]\n [-1]\n [-1]\n [ 1]\n [-1]\n [-1]\n [ 1]\n [ 1]]\n"
     ]
    }
   ],
   "source": [
    "x = data[:, :-1]\n",
    "y = data[:, -1:]\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 215
    }
   ],
   "source": [
    "import neuron\n",
    "importlib.reload(neuron)\n",
    "from neuron import Neuron\n",
    "n = Neuron(3, 1, 0.01)\n",
    "\n",
    "n.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.40166449]\n [1.45821983]\n [0.43616643]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.42641461e-01, 3.49211938e-03, 1.16339003e+00, 2.34857712e-01,\n",
       "        8.16190642e-04, 2.16543412e-01, 2.65375722e-01, 6.14234437e-03]])"
      ]
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "source": [
    "print(n.weights)\n",
    "n.train(x, y)\n",
    "n.train(x, y)\n",
    "n.train(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 1., 0., 0., 1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 208
    }
   ],
   "source": [
    "n.predict(x)"
   ]
  },
  {
   "source": [
    "## Add bias to input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [0., 1., 1., 1.],\n",
       "       [1., 0., 0., 1.],\n",
       "       [1., 0., 1., 1.],\n",
       "       [1., 1., 0., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 202
    }
   ],
   "source": [
    "x_bias = np.ones((x.shape[0], 1))\n",
    "x_train = np.c_[x, x_bias]\n",
    "x_train"
   ]
  },
  {
   "source": [
    "## Create neuron and train\n",
    "* we train by looping over all examples untill the neuron do not fails or we run more then 100 times."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "source": [
    "n = Neuron(x.shape[1], 1)\n",
    "n.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8, 3)\nx[3] : [0 1 1] ,y[3] : [1]\nn.weights : [[0.]\n [0.]\n [0.]] predict x[3] : [array([[0.]])]\ntraing on x[3] err : [[1.]]\n\nx[2] : [0 1 0] ,y[4] : [-1]\nn.weights : [0.  0.2 0.2] [[0.2]] predict x[4] : [array([[1.]])]\ntraing on x[2] err : [[1.96]]\n\nn.weights : [ 0.   -0.08  0.2 ] [[-0.08]] predict x[3] : [array([[1.]])]\ntraing on x[2] err : [[0.7056]]\n\nn.weights : [ 0.    -0.248  0.2  ] [[-0.248]] predict x[2] : [array([[0.]])]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import neuron\n",
    "importlib.reload(neuron)\n",
    "from neuron import Neuron\n",
    "n = Neuron(3, 1)\n",
    "\n",
    "#n.lsm_train(x_train[0], y[0])\n",
    "\n",
    "print(x.shape)\n",
    "print(\"x[3] :\", x[3], \",y[3] :\", y[3])\n",
    "print(\"n.weights :\", n.weights,  \"predict x[3] :\", [n.predict(x[3])])\n",
    "\n",
    "# print(n.weights.flatten())\n",
    "print(\"traing on x[3] err :\", n.train(x[3], y[3]))\n",
    "\n",
    "\n",
    "print(\"\\nx[2] :\", x[2], \",y[4] :\", y[2])\n",
    "print(\"n.weights :\", n.weights.flatten(), n.bias,  \"predict x[4] :\", [n.predict(x[2])])\n",
    "\n",
    "# print(n.weights.flatten())\n",
    "print(\"traing on x[2] err :\", n.train(x[2], y[2]))\n",
    "\n",
    "print(\"\\nn.weights :\", n.weights.flatten(), n.bias,  \"predict x[3] :\", [n.predict(x[3])])\n",
    "print(\"traing on x[2] err :\", n.train(x[2], y[2]))\n",
    "print(\"\\nn.weights :\", n.weights.flatten(), n.bias,  \"predict x[2] :\", [n.predict(x[2])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------ batch : 0 ------\n",
      "train err : [[82.78776443]]\n",
      "------ batch : 1 ------\n",
      "train err : [[63.0616138]]\n",
      "------ batch : 2 ------\n",
      "train err : [[43.75478797]]\n",
      "------ batch : 3 ------\n",
      "train err : [[27.75964946]]\n",
      "------ batch : 4 ------\n",
      "train err : [[36.11541217]]\n",
      "------ batch : 5 ------\n",
      "train err : [[20.32264533]]\n",
      "------ batch : 6 ------\n",
      "train err : [[32.19777247]]\n",
      "------ batch : 7 ------\n",
      "train err : [[28.27411542]]\n",
      "------ batch : 8 ------\n",
      "train err : [[23.80269643]]\n",
      "------ batch : 9 ------\n",
      "train err : [[19.41953482]]\n",
      "predicted :  [[0.]]  actual : [-1]\n",
      "predicted :  [[0.]]  actual : [-1]\n",
      "predicted :  [[1.]]  actual : [-1]\n",
      "predicted :  [[1.]]  actual : [1]\n",
      "predicted :  [[0.]]  actual : [-1]\n",
      "predicted :  [[0.]]  actual : [-1]\n",
      "predicted :  [[1.]]  actual : [1]\n",
      "predicted :  [[1.]]  actual : [1]\n",
      "\n",
      "n.weights : [0.40166449 1.45821983 0.43616643] [[-1.3635599]] predict x[2] : [array([[1.]])]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from neuron import Neuron\n",
    "importlib.reload(neuron)\n",
    "n = Neuron(3, 1, 0.01)\n",
    "\n",
    "\n",
    "def train(size : int):\n",
    "    train_err = 0\n",
    "    for i in range(size):\n",
    "        j = random.randint(0, x.shape[0]-1)\n",
    "        train_err += n.train(x[j], y[j])\n",
    "    print(\"train err :\", train_err)\n",
    "    # print(\"weights :\")\n",
    "    # print(n.weights)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"------ batch :\", i, \"------\")\n",
    "    train(100)\n",
    "\n",
    "\n",
    "for i in range(0, x.shape[0]):\n",
    "    print(\"predicted : \", n.predict(x[i]), \" actual :\", y[i])\n",
    "print(\"\\nn.weights :\", n.weights.flatten(), n.bias,  \"predict x[2] :\", [n.predict(x[2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n------ training done ------\ntraining done on run : 1\nfinal weights :\n[[0.40166449]\n [1.45821983]\n [0.43616643]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n------ training done ------\")\n",
    "print(\"training done on run :\", 1)\n",
    "print(\"final weights :\")\n",
    "print(n.weights)"
   ]
  }
 ]
}